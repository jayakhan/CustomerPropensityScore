{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_encoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayakhan/CustomerPropensityScore/blob/master/10_code/auto_encoder_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Xoc6oxNcS8hI",
        "outputId": "d19eb53d-41df-4dbf-8c1d-5a17544a8870"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Input"
      ],
      "metadata": {
        "id": "IgfTF6oNTCYY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwgllL9BZzEb",
        "outputId": "96592c45-947b-4c5a-e2df-ee951177995c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow_gcs_config\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import nibabel as nib\n",
        "import tensorflow_hub as hub\n",
        "drive.mount('/content/MyDrive/')\n",
        "os.chdir('/content/MyDrive/MyDrive/IDS705_Final') #change to file path on your disk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Train / Val / Test Split\n",
        "subfolders = os.listdir(\"/content/MyDrive/MyDrive/IDS705_Final/Data/Train\")\n",
        "np.random.seed(101)\n",
        "split = np.random.choice([\"Train\",\"Val\",\"Test\"], len(subfolders), p=[0.6, 0.2, 0.2])\n",
        "train_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Train\"]\n",
        "val_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Val\"]\n",
        "test_ids = [subfolders[i] for i,v in enumerate(split) if v==\"Test\"]"
      ],
      "metadata": {
        "id": "capDewJEZ4ao"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Functions\n",
        "def parse_tfrecord(example):\n",
        "  \"\"\"\n",
        "  This function helps in parsing tfrecord files when creating a TF Dataset object\n",
        "  \"\"\"\n",
        "  feature = {'image': tf.io.FixedLenFeature([240, 240, 155, 4], tf.float32),\n",
        "             'label': tf.io.FixedLenFeature([240, 240, 155], tf.int64)}\n",
        "  parsed_example = tf.io.parse_single_example(example, feature)\n",
        "  return parsed_example\n",
        "\n",
        "def get_image_and_label(features):\n",
        "  \"\"\"\n",
        "  Extract Image and Label Object from tfrecord files\n",
        "  \"\"\"\n",
        "  image, label = features['image'], features['label']\n",
        "  return image, label\n",
        "\n",
        "def get_image_and_label_auto(features):\n",
        "  \"\"\"\n",
        "  Extract Image and Label Object from tfrecord files\n",
        "  \"\"\"\n",
        "  image = features['image']\n",
        "  return image, image\n",
        "\n",
        "def get_dataset(tfrecord_names):\n",
        "  \"\"\"\n",
        "  Create TF dataset files that can be fed into model functions\n",
        "  \"\"\"\n",
        "  dataset = (tf.data.TFRecordDataset(tfrecord_names)\n",
        "             .map(parse_tfrecord)\n",
        "             .map(get_image_and_label_auto))\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "AIEqR7NMZ-9P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataset objects\n",
        "train_dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in train_ids])\n",
        "test_dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in test_ids])\n",
        "val_dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in val_ids])\n",
        "mini_dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in subfolders[100:228]])\n",
        "minival_dataset = get_dataset([f'/content/MyDrive/MyDrive/IDS705_Final/Data/train_tf/{sf}.tfrecord' for sf in subfolders[500:508]])"
      ],
      "metadata": {
        "id": "IxXwC_DDaBCx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(input_layer):\n",
        "  # Elements in layer represent in this order batchSize, height, width, channels\n",
        "  print(\"*****Encoder*****\", input_layer)\n",
        "\n",
        "  x4 = tf.keras.layers.BatchNormalization()(input_layer)\n",
        "  x4 = tf.keras.layers.Conv3D( 4, 3, strides=(1,1,1), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Conv3D( 4, 3, strides=(1,1,1), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
        "  x4 = tf.keras.layers.Dropout(0.15)(x4)\n",
        "\n",
        "  print(\"x1\", x4.shape)\n",
        "\n",
        "  x8 = tf.keras.layers.Conv3D( 8, 3, strides=(2,2,2), activation='relu', padding='same')(x4)\n",
        "  x8 = tf.keras.layers.BatchNormalization()(x8)\n",
        "  x8 = tf.keras.layers.Conv3D( 8, 3, strides=(1,1,1), activation='relu', padding='same')(x8)\n",
        "  x8 = tf.keras.layers.BatchNormalization()(x8)\n",
        "  x8 = tf.keras.layers.Dropout(0.15)(x8)\n",
        "\n",
        "\n",
        "  print(\"x2\", x8.shape)\n",
        "\n",
        "  x16 = tf.keras.layers.Conv3D(16, 3, strides=(2,2,2), activation='relu', padding='same')(x8)\n",
        "  x16 = tf.keras.layers.BatchNormalization()(x16)\n",
        "  x16 = tf.keras.layers.Conv3D(16, 3, strides=(1,1,1), activation='relu', padding='same')(x16)\n",
        "  x16 = tf.keras.layers.BatchNormalization()(x16)\n",
        "  x16 = tf.keras.layers.Dropout(0.15)(x16)\n",
        "\n",
        "  print(\"x3\", x16.shape)\n",
        "\n",
        "  x32 = tf.keras.layers.Conv3D(32, 3, strides=(2,2,2), activation='relu', padding='same')(x16)\n",
        "  x32 = tf.keras.layers.BatchNormalization()(x32)\n",
        "  x32 = tf.keras.layers.Conv3D(32, 3, strides=(1,1,1), activation='relu', padding='same')(x32)\n",
        "  x32 = tf.keras.layers.BatchNormalization()(x32)\n",
        "  x32 = tf.keras.layers.Dropout(0.15)(x32)\n",
        "\n",
        "  print(\"x4\", x32.shape)\n",
        "\n",
        "  x64 = tf.keras.layers.Conv3D(64, 3, strides=(2,2,2), activation='relu', padding='same')(x32)\n",
        "  x64 = tf.keras.layers.BatchNormalization()(x64)\n",
        "  x64 = tf.keras.layers.Conv3D(64, 3, strides=(1,1,1), activation='relu', padding='same')(x64)\n",
        "  x64 = tf.keras.layers.BatchNormalization()(x64)\n",
        "  x64 = tf.keras.layers.Dropout(0.15)(x64)\n",
        "\n",
        "  print(\"x5\", x64.shape)\n",
        "\n",
        "  x128 = tf.keras.layers.Conv3D(128, 3, strides=(2,2,2), activation='relu', padding='same')(x64)\n",
        "  x128 = tf.keras.layers.BatchNormalization()(x128)\n",
        "  x128 = tf.keras.layers.Conv3D(128, 3, strides=(1,1,1), activation='relu', padding='same')(x128)\n",
        "  x128 = tf.keras.layers.BatchNormalization()(x128)\n",
        "  x128 = tf.keras.layers.Dropout(0.15)(x128)\n",
        "\n",
        "  print(\"x6\", x128.shape)\n",
        "\n",
        "  return x128\n"
      ],
      "metadata": {
        "id": "xomunduXbdvM"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(encoded_layer):\n",
        "  print(\"*****Decoder*****\", encoded_layer)\n",
        "\n",
        "  x64 = tf.keras.layers.Conv3DTranspose(64, 3, strides=(1,1,1), activation='relu')(encoded_layer)\n",
        "  x64 = tf.keras.layers.Conv3DTranspose(64, 3, strides=(2,2,2), activation='relu', padding='same')(x64)\n",
        "  x64 = tf.keras.layers.Cropping3D(cropping=((1,2), (1,2), (1,1)))(x64)\n",
        "  x64 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x64)\n",
        "  print(\"x1\", x64.shape)\n",
        "\n",
        "  \n",
        "  x32 = tf.keras.layers.Conv3DTranspose(32, 3, strides=(1,1,1), activation='relu')(x64)\n",
        "  x32 = tf.keras.layers.Conv3DTranspose(32, 3, strides=(2,2,2), activation='relu', padding='same')(x32)\n",
        "  x32 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x32)\n",
        "  x32 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x32)\n",
        "\n",
        "  print(\"x2\", x32.shape)\n",
        "\n",
        "  x16 = tf.keras.layers.Conv3DTranspose(16, 3, strides=(1,1,1), activation='relu')(x32)\n",
        "  x16 = tf.keras.layers.Conv3DTranspose(16, 3, strides=(2,2,2), activation='relu', padding='same')(x16)\n",
        "  x16 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x16)\n",
        "  x16 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,2)))(x16)\n",
        "\n",
        "  print(\"x4\", x16.shape)\n",
        "\n",
        "  x8 = tf.keras.layers.Conv3DTranspose(8, 3, strides=(1,1,1), activation='relu')(x16)\n",
        "  x8 = tf.keras.layers.Conv3DTranspose(8, 3, strides=(2,2,2), activation='relu', padding='same')(x8)\n",
        "  x8 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x8)\n",
        "  x8 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x8)\n",
        "\n",
        "  print(\"x5\", x8.shape)\n",
        "\n",
        "  x4 = tf.keras.layers.Conv3DTranspose(4, 3, strides=(1,1,1), activation='relu')(x8)\n",
        "  x4 = tf.keras.layers.Conv3DTranspose(4, 3, strides=(2,2,2), activation='relu', padding='same')(x4)\n",
        "  x4 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,1)))(x4)\n",
        "  x4 = tf.keras.layers.Cropping3D(cropping=((1,1), (1,1), (1,2)))(x4)\n",
        "\n",
        "\n",
        "\n",
        "  print(\"x6\", x4.shape)\n",
        "\n",
        "  return x4\n",
        "  \n"
      ],
      "metadata": {
        "id": "xfKx3a4mf6wt"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Encoder and Deocder layers\n",
        "from keras.models import Model, Input\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(240,240,155,4))\n",
        "e_l = encoder(input_layer)\n",
        "output = decoder(e_l)\n",
        "\n",
        "\n",
        "autoencoder = Model(inputs = input_layer, outputs = output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0_SCrLis2p",
        "outputId": "0902e663-f9a8-4080-a033-abba32deea9e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Encoder***** KerasTensor(type_spec=TensorSpec(shape=(None, 240, 240, 155, 4), dtype=tf.float32, name='input_44'), name='input_44', description=\"created by layer 'input_44'\")\n",
            "x1 (None, 240, 240, 155, 4)\n",
            "x2 (None, 120, 120, 78, 8)\n",
            "x3 (None, 60, 60, 39, 16)\n",
            "x4 (None, 30, 30, 20, 32)\n",
            "x5 (None, 15, 15, 10, 64)\n",
            "x6 (None, 8, 8, 5, 128)\n",
            "*****Decoder***** KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 5, 128), dtype=tf.float32, name=None), name='dropout_7/Identity:0', description=\"created by layer 'dropout_7'\")\n",
            "x1 (None, 15, 15, 10, 64)\n",
            "x2 (None, 30, 30, 20, 32)\n",
            "x4 (None, 60, 60, 39, 16)\n",
            "x5 (None, 120, 120, 78, 8)\n",
            "x6 (None, 240, 240, 155, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as k\n",
        "\n",
        "class DiceLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, smooth=1e-6, gama=2):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.name = 'NDL'\n",
        "        self.smooth = smooth\n",
        "        self.gama = gama\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        inter = k.sum(y_true[:,:,-1]*y_pred[:,:,-1])\n",
        "        return (2*inter + 1)/(k.sum(y_true[:,:,-1]) + k.sum(y_pred[:,:,-1]) + 1)"
      ],
      "metadata": {
        "id": "_GgmvRR-V9zo"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DICE Coefficent definition used as a metric in compilation\n",
        "def dice_coef(y_pred, y_true):\n",
        "    inter = k.sum(y_true[:,:,-1]*y_pred[:,:,-1])\n",
        "    return (2*inter + 1)/(k.sum(y_true[:,:,-1]) + k.sum(y_pred[:,:,-1]) + 1)"
      ],
      "metadata": {
        "id": "7DqJNSU6SioA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1e-3\n",
        "autoencoder.compile(loss=DiceLoss(), optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmgO9tIMnRl_",
        "outputId": "32fce1cd-4ea3-4242-9afd-0402cab54e9e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_44 (InputLayer)       [(None, 240, 240, 155, 4  0         \n",
            "                             )]                                  \n",
            "                                                                 \n",
            " batch_normalization_551 (Ba  (None, 240, 240, 155, 4)  16       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_510 (Conv3D)         (None, 240, 240, 155, 4)  436       \n",
            "                                                                 \n",
            " batch_normalization_552 (Ba  (None, 240, 240, 155, 4)  16       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_511 (Conv3D)         (None, 240, 240, 155, 4)  436       \n",
            "                                                                 \n",
            " batch_normalization_553 (Ba  (None, 240, 240, 155, 4)  16       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 240, 240, 155, 4)  0         \n",
            "                                                                 \n",
            " conv3d_512 (Conv3D)         (None, 120, 120, 78, 8)   872       \n",
            "                                                                 \n",
            " batch_normalization_554 (Ba  (None, 120, 120, 78, 8)  32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_513 (Conv3D)         (None, 120, 120, 78, 8)   1736      \n",
            "                                                                 \n",
            " batch_normalization_555 (Ba  (None, 120, 120, 78, 8)  32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 120, 120, 78, 8)   0         \n",
            "                                                                 \n",
            " conv3d_514 (Conv3D)         (None, 60, 60, 39, 16)    3472      \n",
            "                                                                 \n",
            " batch_normalization_556 (Ba  (None, 60, 60, 39, 16)   64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_515 (Conv3D)         (None, 60, 60, 39, 16)    6928      \n",
            "                                                                 \n",
            " batch_normalization_557 (Ba  (None, 60, 60, 39, 16)   64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 60, 60, 39, 16)    0         \n",
            "                                                                 \n",
            " conv3d_516 (Conv3D)         (None, 30, 30, 20, 32)    13856     \n",
            "                                                                 \n",
            " batch_normalization_558 (Ba  (None, 30, 30, 20, 32)   128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_517 (Conv3D)         (None, 30, 30, 20, 32)    27680     \n",
            "                                                                 \n",
            " batch_normalization_559 (Ba  (None, 30, 30, 20, 32)   128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 30, 30, 20, 32)    0         \n",
            "                                                                 \n",
            " conv3d_518 (Conv3D)         (None, 15, 15, 10, 64)    55360     \n",
            "                                                                 \n",
            " batch_normalization_560 (Ba  (None, 15, 15, 10, 64)   256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_519 (Conv3D)         (None, 15, 15, 10, 64)    110656    \n",
            "                                                                 \n",
            " batch_normalization_561 (Ba  (None, 15, 15, 10, 64)   256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 15, 15, 10, 64)    0         \n",
            "                                                                 \n",
            " conv3d_520 (Conv3D)         (None, 8, 8, 5, 128)      221312    \n",
            "                                                                 \n",
            " batch_normalization_562 (Ba  (None, 8, 8, 5, 128)     512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3d_521 (Conv3D)         (None, 8, 8, 5, 128)      442496    \n",
            "                                                                 \n",
            " batch_normalization_563 (Ba  (None, 8, 8, 5, 128)     512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 5, 128)      0         \n",
            "                                                                 \n",
            " conv3d_transpose_370 (Conv3  (None, 10, 10, 7, 64)    221248    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv3d_transpose_371 (Conv3  (None, 20, 20, 14, 64)   110656    \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " cropping3d_155 (Cropping3D)  (None, 17, 17, 12, 64)   0         \n",
            "                                                                 \n",
            " cropping3d_156 (Cropping3D)  (None, 15, 15, 10, 64)   0         \n",
            "                                                                 \n",
            " conv3d_transpose_372 (Conv3  (None, 17, 17, 12, 32)   55328     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv3d_transpose_373 (Conv3  (None, 34, 34, 24, 32)   27680     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " cropping3d_157 (Cropping3D)  (None, 32, 32, 22, 32)   0         \n",
            "                                                                 \n",
            " cropping3d_158 (Cropping3D)  (None, 30, 30, 20, 32)   0         \n",
            "                                                                 \n",
            " conv3d_transpose_374 (Conv3  (None, 32, 32, 22, 16)   13840     \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv3d_transpose_375 (Conv3  (None, 64, 64, 44, 16)   6928      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " cropping3d_159 (Cropping3D)  (None, 62, 62, 42, 16)   0         \n",
            "                                                                 \n",
            " cropping3d_160 (Cropping3D)  (None, 60, 60, 39, 16)   0         \n",
            "                                                                 \n",
            " conv3d_transpose_376 (Conv3  (None, 62, 62, 41, 8)    3464      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv3d_transpose_377 (Conv3  (None, 124, 124, 82, 8)  1736      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " cropping3d_161 (Cropping3D)  (None, 122, 122, 80, 8)  0         \n",
            "                                                                 \n",
            " cropping3d_162 (Cropping3D)  (None, 120, 120, 78, 8)  0         \n",
            "                                                                 \n",
            " conv3d_transpose_378 (Conv3  (None, 122, 122, 80, 4)  868       \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " conv3d_transpose_379 (Conv3  (None, 244, 244, 160, 4)  436      \n",
            " DTranspose)                                                     \n",
            "                                                                 \n",
            " cropping3d_163 (Cropping3D)  (None, 242, 242, 158, 4)  0        \n",
            "                                                                 \n",
            " cropping3d_164 (Cropping3D)  (None, 240, 240, 155, 4)  0        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,456\n",
            "Trainable params: 1,328,440\n",
            "Non-trainable params: 1,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 4\n",
        "shufflesize = 8\n",
        "mini_dataset_trainable = mini_dataset.shuffle(shufflesize).batch(batchsize)\n",
        "minival_dataset_validable = minival_dataset.batch(batchsize)\n",
        "train_dataset_trainable = train_dataset.shuffle(shufflesize).batch(batchsize)\n",
        "val_dataset_validable = val_dataset.batch(batchsize)"
      ],
      "metadata": {
        "id": "muk7qrVro3N6"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "OUOn568fR_UV"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "auto_enc = autoencoder.fit(train_dataset_trainable, epochs = epochs, batch_size = 4, shuffle = False,validation_data=val_dataset_validable, callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
        "\n",
        "loss = auto_enc.history['loss']\n",
        "val_loss = auto_enc.history['val_loss']\n",
        "epochs = range(epochs)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'go', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "qyANFfcRpvXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd11552-81cd-4611-8a6c-76d9d1aff386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "    143/Unknown - 854s 6s/step - loss: 1.0590e-06"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot([1, 2], loss, 'bo', label='Training loss')\n",
        "plt.plot([1, 2], val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.yscale(\"log\")\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "4FgVauW9jdo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e6de2a78-3655-4fe4-de76-01d821beece2"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}